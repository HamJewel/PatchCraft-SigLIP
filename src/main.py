import os
import torch
import pandas as pd
from tqdm import tqdm
from Model.model import Model
from Model.dataset import ImgDataset, collate_fn
from Model.utils import predict
from torch.utils.data import DataLoader


@torch.no_grad()
def test():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model_name = 'ViT-B-16-SigLIP-512'
    tokenizer_name = 'hf-hub:./src/Configs'
    checkpoint = torch.load('./src/Configs/best.pt', map_location=device)
    model = Model(model_name, tokenizer_name).to(device)
    print('Model Initialized')
    model.load_state_dict(checkpoint['model_state_dict'])
    print('Model State Dict Loaded')

    data_path = './testdata'
    images = sorted([img for img in os.listdir(data_path) if img.endswith(('.png', '.jpg', '.jpeg'))])
    img_ids = [img.split('.')[0] for img in images]
    test_data = [(f'{data_path}/{img}', -1) for img in images]
    test_set = ImgDataset(test_data, train=False)
    test_loader = DataLoader(test_set, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=6)
    print('Test Set Loaded')

    texts = ['Image created by humans', 'Image generated by AI']
    tokens = model.tokenizer(texts, context_length=model.clip.context_length).to(device)
    print('Prompts Generated')

    print('Test Set Size:', len(test_set))
    model.eval()
    labels = []
    for imgs, _, rts, pts in tqdm(test_loader, desc='Testing Steps', unit='it', leave=True):
        imgs, rts, pts = imgs.to(device), rts.to(device), pts.to(device)
        logits = model(imgs, tokens, rts, pts).cpu()
        y = predict(logits).tolist()
        labels.extend(y)

    print('Prediction Finished')
    df = pd.DataFrame({'id': img_ids, 'label': labels})
    df.to_csv(f'./cla_pre.csv', index=False, header=False)
    print('Result Saved')


if __name__ == '__main__':
    test()
